GIẢI THÍCH THUẬT TOÁN HỒI QUY TUYẾN TÍNH VỚI MINI-BATCH GRADIENT DESCENT

1. Định nghĩa:
- Batch size m: số mẫu được xử lý trong một lần cập nhật
- X̄: ma trận đầu vào mở rộng kích thước (N,2)
- θ = [w b]ᵀ: vector tham số
- y: vector giá trị thực

2. Phương trình hồi quy cho m mẫu:
Ŷ = X̄θ

3. Hàm mất mát trung bình cho m mẫu:
L(θ) = (1/m)Σᵢ(ŷᵢ - yᵢ)²
     = (1/m)Σᵢ(X̄ᵢθ - yᵢ)²

4. Gradient trung bình:
∇L(θ) = (2/m)Σᵢ[X̄ᵢᵀ(X̄ᵢθ - yᵢ)]

5. Quy trình thuật toán:
- Khởi tạo θ ngẫu nhiên
- Lặp qua epoch_max lần:
  + Chia dữ liệu thành các mini-batch kích thước m
  + Với mỗi mini-batch:
    * Tính gradient trung bình cho m mẫu
    * Cập nhật: θ = θ - α∇L(θ)

Ưu điểm:
- Cân bằng giữa SGD và Batch GD
- Ổn định hơn SGD
- Nhanh hơn Batch GD

Nhược điểm:
- Cần chọn batch size phù hợp
- Phức tạp hơn SGD và Batch GD 